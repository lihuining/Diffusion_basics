{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6dc7f68",
   "metadata": {},
   "source": [
    "## SDXL text encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91371683-c8f5-4e8b-b3e1-91e9f946e11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, PretrainedConfig\n",
    "#from train_controlnet_sdxl_odps_sub import import_model_class_from_model_name_or_path\n",
    "\n",
    "pretrained_model_name_or_path = \"/mnt/workspace/workgroup_share/lhn/models/stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "weight_dtype = torch.bfloat16\n",
    "device = \"cuda\"\n",
    "prompt = 'photorealistic, ultra-detailed, cinematic photo, raw photo, highrek, 4k, professional, ultra-detailed, hires, 8k, Super Detail,masterpiece,best quality,highly detailed,good compositon,' \n",
    "variant = None\n",
    "revision = None\n",
    "\n",
    "# Load the tokenizers\n",
    "tokenizer_one = AutoTokenizer.from_pretrained(\n",
    "    pretrained_model_name_or_path,\n",
    "    subfolder=\"tokenizer\",\n",
    "    revision=revision,\n",
    "    use_fast=False,\n",
    ")\n",
    "tokenizer_two = AutoTokenizer.from_pretrained(\n",
    "    pretrained_model_name_or_path,\n",
    "    subfolder=\"tokenizer_2\",\n",
    "    revision=revision,\n",
    "    use_fast=False,\n",
    ")\n",
    "\n",
    "# # import correct text encoder classes\n",
    "# text_encoder_cls_one = import_model_class_from_model_name_or_path(\n",
    "#     pretrained_model_name_or_path, revision\n",
    "# )\n",
    "# text_encoder_cls_two = import_model_class_from_model_name_or_path(\n",
    "#     pretrained_model_name_or_path, revision, subfolder=\"text_encoder_2\"\n",
    "# )\n",
    "\n",
    "# text_encoder_one = text_encoder_cls_one.from_pretrained(\n",
    "#     pretrained_model_name_or_path, subfolder=\"text_encoder\", revision=revision, variant=variant\n",
    "# )\n",
    "# text_encoder_two = text_encoder_cls_two.from_pretrained(\n",
    "#     pretrained_model_name_or_path, subfolder=\"text_encoder_2\", revision=revision, variant=variant\n",
    "# )\n",
    "\n",
    "# text_encoders = [text_encoder_one, text_encoder_two]\n",
    "# tokenizers = [tokenizer_one, tokenizer_two]\n",
    "# text_encoder_one.to(device, dtype=weight_dtype)\n",
    "# text_encoder_two.to(device, dtype=weight_dtype)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e920a7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tokenizers[0]\n",
    "text_encoder = text_encoders[0]\n",
    "text_inputs = tokenizer(\n",
    "    prompt,\n",
    "    padding=\"max_length\",\n",
    "    max_length=tokenizer.model_max_length,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "text_input_ids = text_inputs.input_ids\n",
    "prompt_embeds = text_encoder(\n",
    "    text_input_ids.to(text_encoder.device),\n",
    "    output_hidden_states=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ded150c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPooling(last_hidden_state=tensor([[[-0.3887,  0.0226, -0.0508,  ..., -0.4922, -0.3086,  0.0669],\n",
       "         [-0.3457,  0.8047,  1.5391,  ..., -1.9766, -0.5781, -0.4785],\n",
       "         [ 1.3750, -1.0156,  0.6602,  ..., -0.3574,  0.3730, -1.0625],\n",
       "         ...,\n",
       "         [ 0.7734, -0.4961,  1.9766,  ...,  0.3320, -1.0625,  0.1128],\n",
       "         [ 0.7383, -0.5078,  2.0156,  ...,  0.3535, -1.0391,  0.0806],\n",
       "         [ 0.8086, -0.4492,  2.3750,  ...,  0.4629, -1.0234, -0.0576]]],\n",
       "       device='cuda:0', dtype=torch.bfloat16, grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 1.5234e+00, -1.1719e+00,  1.2109e+00, -3.8086e-01, -2.7969e+00,\n",
       "         -1.1797e+00, -9.4531e-01,  2.5977e-01, -8.3984e-01,  8.3984e-01,\n",
       "         -2.7734e-01,  6.4453e-01, -5.9375e-01, -7.2266e-01,  8.0859e-01,\n",
       "          1.0469e+00, -7.5391e-01,  2.1562e+00, -1.3750e+00,  2.0801e-01,\n",
       "          2.2188e+00, -8.9062e-01, -8.3594e-01, -1.9062e+00, -2.3145e-01,\n",
       "          4.1797e-01,  1.2031e+00, -5.5664e-02, -7.2754e-02, -1.4141e+00,\n",
       "         -4.4727e-01, -6.2012e-02, -7.3047e-01,  5.2734e-01, -2.1875e+00,\n",
       "         -2.0508e-01, -1.1250e+00,  3.5156e-02,  7.6953e-01,  5.9766e-01,\n",
       "          1.5625e+00, -9.1406e-01,  3.4375e-01,  9.3262e-02, -1.0703e+00,\n",
       "         -5.9766e-01,  1.3359e+00, -3.0000e+00, -3.5156e-02,  3.4180e-01,\n",
       "          1.8906e+00,  4.9219e-01,  2.2754e-01,  6.4844e-01,  3.3594e-01,\n",
       "         -2.3125e+00,  1.1953e+00, -6.7969e-01,  9.6484e-01, -1.3594e+00,\n",
       "         -2.2363e-01, -6.6797e-01, -1.8750e-01,  1.0781e+00,  1.3046e-03,\n",
       "          3.4766e-01, -6.6016e-01, -2.0605e-01,  3.3936e-02,  5.0000e-01,\n",
       "          4.2188e-01,  1.4688e+00,  7.5781e-01,  6.0547e-01,  8.5156e-01,\n",
       "          9.1016e-01, -7.6172e-01,  2.2852e-01, -1.0938e+00,  1.4297e+00,\n",
       "          4.7656e-01, -6.9922e-01,  1.8066e-01, -1.0859e+00, -1.2891e+00,\n",
       "         -9.4141e-01, -1.3359e+00, -9.2969e-01,  3.6523e-01, -6.9531e-01,\n",
       "         -3.0273e-01, -3.7344e+00, -1.9531e+00,  1.7109e+00,  1.0547e+00,\n",
       "          8.2031e-01,  4.3164e-01,  1.8848e-01, -1.4062e+00,  3.2812e-01,\n",
       "         -2.0312e-01,  2.0874e-02, -3.2227e-01,  5.1562e-01, -3.6133e-02,\n",
       "         -5.2734e-01,  9.2188e-01, -2.6953e-01,  4.2383e-01, -1.1875e+00,\n",
       "         -1.4375e+00, -1.1719e+00, -5.5078e-01, -4.5508e-01, -6.2891e-01,\n",
       "         -5.9766e-01, -6.9141e-01, -9.1016e-01,  9.5703e-01,  1.3516e+00,\n",
       "          1.3594e+00,  9.1016e-01, -1.1670e-01,  3.4570e-01, -7.6562e-01,\n",
       "         -3.4961e-01,  3.4180e-01,  4.8242e-01,  3.4375e-01, -2.5586e-01,\n",
       "         -1.5234e-01,  1.6328e+00, -5.1562e-01,  1.8652e-01, -9.5312e-01,\n",
       "         -8.6719e-01,  7.9297e-01,  1.3281e-01,  6.6406e-01,  1.2188e+00,\n",
       "          8.0469e-01, -1.2344e+00, -8.1250e-01, -1.0303e-01, -2.2656e-01,\n",
       "          2.4219e+00, -9.5312e-01, -1.3672e+00,  4.5117e-01, -6.8750e-01,\n",
       "          5.8984e-01, -6.7578e-01,  5.8594e-01, -6.2109e-01, -8.4375e-01,\n",
       "         -2.0215e-01,  1.1094e+00,  1.3574e-01, -2.0605e-01, -1.1172e+00,\n",
       "         -1.2344e+00,  1.4355e-01,  5.9766e-01, -1.6016e+00, -9.2163e-03,\n",
       "         -4.1602e-01,  1.7656e+00, -1.3281e+00, -1.4160e-01,  2.9883e-01,\n",
       "         -6.0547e-01, -7.6953e-01, -1.3770e-01,  1.0000e+00, -2.8906e-01,\n",
       "         -5.4297e-01, -8.0566e-02, -1.0234e+00,  7.5781e-01,  1.0391e+00,\n",
       "         -1.3281e+00, -3.0273e-01,  5.8350e-02,  5.4688e-01, -8.2812e-01,\n",
       "          4.0234e-01, -3.2227e-01,  2.7148e-01,  1.1484e+00, -1.0703e+00,\n",
       "         -8.6328e-01, -3.8086e-01, -8.1250e-01, -2.4121e-01,  1.6895e-01,\n",
       "          6.0547e-01,  5.6250e-01,  8.1641e-01,  4.3750e-01, -2.0996e-01,\n",
       "         -1.0547e+00,  7.2656e-01,  1.1719e+00, -1.5625e-01, -3.8281e-01,\n",
       "         -1.9531e-01, -1.6016e+00, -3.6328e-01, -1.4453e+00, -8.0469e-01,\n",
       "         -6.0938e-01, -2.9688e+00, -1.9688e+00, -2.1191e-01,  4.7656e-01,\n",
       "          1.4297e+00, -1.0781e+00,  9.0625e-01,  8.7891e-01,  2.3438e+00,\n",
       "         -6.1328e-01,  2.5195e-01,  1.5469e+00,  1.2578e+00,  1.1484e+00,\n",
       "         -4.4189e-02, -1.1875e+00,  3.8867e-01, -1.4453e+00, -2.1387e-01,\n",
       "          6.1719e-01,  8.1641e-01,  1.3379e-01, -1.4160e-01, -2.3633e-01,\n",
       "          4.3164e-01, -5.3125e-01,  5.0391e-01,  2.3340e-01,  9.0625e-01,\n",
       "          4.0430e-01,  2.9883e-01,  1.0625e+00, -1.2598e-01, -1.0469e+00,\n",
       "         -2.1250e+00, -6.8750e-01, -3.3984e-01,  7.1875e-01,  1.3047e+00,\n",
       "         -1.9375e+00,  4.5508e-01,  1.4375e+00,  2.0312e+00, -1.7344e+00,\n",
       "         -2.1387e-01,  4.4336e-01,  1.1016e+00, -5.5078e-01, -6.6406e-01,\n",
       "         -4.5312e-01,  4.8828e-01, -4.7070e-01, -8.8281e-01,  1.1875e+00,\n",
       "         -1.4297e+00, -2.5781e-01, -1.7383e-01, -1.6406e+00,  1.1797e+00,\n",
       "         -2.6367e-01, -7.1875e-01, -6.7578e-01, -1.0703e+00, -1.0625e+00,\n",
       "          7.6172e-01, -1.4062e+00, -1.1641e+00,  8.2812e-01,  5.0000e-01,\n",
       "          7.5000e-01,  2.8906e-01, -1.6094e+00, -5.9375e-01, -1.8311e-02,\n",
       "         -3.5938e-01, -6.5625e-01, -2.1484e-01,  1.8438e+00,  6.2891e-01,\n",
       "         -4.9805e-01, -4.6484e-01, -6.0156e-01, -7.3828e-01,  7.5391e-01,\n",
       "         -8.1250e-01,  1.3477e-01,  1.2146e-02,  1.4219e+00, -4.9805e-01,\n",
       "          1.1250e+00,  1.0469e+00,  9.3384e-03,  2.3340e-01, -3.3984e-01,\n",
       "          1.1328e+00, -2.4658e-02,  5.2344e-01, -1.4587e-02,  2.8125e-01,\n",
       "         -1.9531e+00,  2.3047e-01,  3.5352e-01, -1.2793e-01, -7.7344e-01,\n",
       "         -1.9297e+00,  4.3457e-02, -1.6562e+00,  1.7891e+00,  2.2363e-01,\n",
       "         -1.0625e+00,  3.7500e-01, -2.8711e-01, -1.8457e-01, -3.7695e-01,\n",
       "          5.2734e-01,  1.4062e+00,  3.3398e-01, -3.1055e-01,  3.5156e-01,\n",
       "         -2.0703e-01, -8.7402e-02, -1.2266e+00, -4.1748e-02,  4.1504e-02,\n",
       "         -1.5469e+00,  9.6094e-01,  4.5312e-01, -2.5635e-02,  8.6328e-01,\n",
       "         -2.5781e-01,  1.2812e+00, -1.4062e-01, -2.2754e-01, -3.5352e-01,\n",
       "         -1.1250e+00,  1.7734e+00,  3.5938e-01,  1.3516e+00, -1.4219e+00,\n",
       "         -3.4766e-01, -9.6680e-02, -1.8203e+00,  7.2656e-01, -3.4961e-01,\n",
       "          1.1797e+00,  2.9297e-01,  7.8516e-01, -5.7422e-01, -7.6172e-01,\n",
       "         -8.6328e-01, -1.7578e+00, -1.4062e-01, -6.8750e-01,  6.1768e-02,\n",
       "         -3.5742e-01, -2.2031e+00, -1.0938e+00, -6.3672e-01,  1.2500e+00,\n",
       "         -7.4609e-01,  6.2891e-01, -3.6328e-01,  7.0703e-01, -5.6641e-01,\n",
       "         -2.2344e+00, -6.7578e-01, -8.9062e-01, -3.9062e-01,  7.8516e-01,\n",
       "         -3.7695e-01, -1.7090e-01,  9.8633e-02,  6.7188e-01, -9.8438e-01,\n",
       "          9.4922e-01,  8.5938e-02,  1.1562e+00, -2.5269e-02,  3.0859e-01,\n",
       "          3.0469e-01,  1.6484e+00, -5.5859e-01, -3.4570e-01, -7.4609e-01,\n",
       "          4.0430e-01,  7.1875e-01,  2.0312e+00,  7.0312e-02, -1.9531e-01,\n",
       "         -3.5938e-01, -1.7266e+00, -1.3438e+00, -9.3750e-02, -6.5234e-01,\n",
       "          1.2734e+00, -9.5703e-01, -5.6250e-01, -3.4180e-02, -3.1055e-01,\n",
       "         -5.6641e-01, -6.8359e-02, -9.2969e-01, -2.1875e+00, -2.5000e+00,\n",
       "          3.9062e-01, -9.7656e-02,  2.1289e-01,  6.1328e-01, -9.2969e-01,\n",
       "          5.3516e-01, -1.5625e-01, -1.0625e+00, -1.4297e+00, -6.0938e-01,\n",
       "          8.3594e-01,  9.0625e-01, -1.0742e-01, -1.3203e+00,  2.0605e-01,\n",
       "          4.6094e-01,  7.7734e-01,  2.4609e-01, -6.8359e-01, -7.9688e-01,\n",
       "         -1.1953e+00, -1.4531e+00, -7.1875e-01,  6.5430e-02,  1.2109e+00,\n",
       "         -5.6641e-01, -6.2988e-02, -5.1953e-01, -1.2500e+01,  9.8438e-01,\n",
       "         -6.0938e-01,  3.6914e-01,  5.2185e-03,  8.7891e-01, -4.9414e-01,\n",
       "         -1.0234e+00,  1.2188e+00, -1.7969e-01,  3.1641e-01,  3.7109e-02,\n",
       "         -1.2734e+00, -8.3984e-02,  1.3984e+00, -5.1562e-01, -3.1055e-01,\n",
       "          1.2969e+00, -5.8594e-01,  4.7656e-01,  2.4062e+00, -1.0469e+00,\n",
       "          2.9531e+00, -1.3438e+00, -3.2227e-01,  1.7188e-01, -8.9062e-01,\n",
       "          8.6719e-01, -4.0283e-02, -3.3691e-02, -3.0859e-01, -2.3438e-02,\n",
       "         -6.2109e-01, -1.2012e-01,  7.8516e-01,  1.4922e+00, -1.5000e+00,\n",
       "          1.1328e+00, -1.1572e-01, -1.3125e+00, -2.4688e+00, -4.9609e-01,\n",
       "         -1.8516e+00, -9.8438e-01,  6.0547e-01, -3.6133e-01, -4.1797e-01,\n",
       "         -2.4219e+00, -9.1797e-02,  1.3906e+00,  3.8477e-01, -1.6484e+00,\n",
       "          2.1484e-01,  3.3984e-01, -1.9219e+00,  4.6875e-01,  1.0312e+00,\n",
       "          6.2109e-01,  7.3047e-01, -1.3750e+00, -5.3516e-01,  3.3203e-01,\n",
       "         -4.2773e-01, -1.3438e+00, -4.2188e-01, -3.1836e-01,  4.5703e-01,\n",
       "          2.6953e-01, -7.6172e-01, -1.4453e-01,  9.6484e-01, -5.6250e-01,\n",
       "         -2.0938e+00, -3.2617e-01, -9.4922e-01, -1.3125e+00, -7.5391e-01,\n",
       "         -1.9766e+00, -5.2734e-02,  4.6680e-01,  4.8438e-01, -1.8945e-01,\n",
       "         -1.5625e+00, -3.5156e-01, -1.1406e+00,  4.2773e-01,  5.4297e-01,\n",
       "          4.8047e-01,  5.2734e-01, -1.4844e-01,  1.8828e+00, -4.1602e-01,\n",
       "         -2.2188e+00, -4.3164e-01, -7.5000e-01,  8.1250e-01,  5.9814e-02,\n",
       "         -9.7656e-01, -7.3853e-03, -1.6797e-01,  5.0000e-01,  8.3203e-01,\n",
       "          2.7734e-01,  1.0234e+00,  1.4609e+00, -1.4297e+00, -1.5703e+00,\n",
       "         -1.0547e+00, -1.4766e+00,  6.1719e-01, -8.6328e-01, -1.6406e-01,\n",
       "         -2.0781e+00,  2.8931e-02,  8.5547e-01,  1.7031e+00,  3.9258e-01,\n",
       "         -6.2500e-01, -2.9062e+00,  6.0547e-01,  2.0469e+00, -5.6641e-01,\n",
       "          9.4531e-01, -1.1953e+00, -5.6250e-01, -3.5352e-01, -2.2363e-01,\n",
       "          9.8438e-01,  1.7383e-01,  1.6016e-01,  7.6172e-01,  7.1777e-02,\n",
       "         -1.3672e+00, -9.7656e-01,  1.5625e-01,  8.9062e-01, -8.8281e-01,\n",
       "          5.7422e-01,  4.2188e-01,  8.7109e-01,  9.3262e-02, -5.0781e-01,\n",
       "         -9.2188e-01, -1.6479e-02, -4.6680e-01, -1.5938e+00,  2.7969e+00,\n",
       "          4.3359e-01,  1.3379e-01, -7.4219e-01, -6.7969e-01, -9.2188e-01,\n",
       "         -6.7188e-01,  6.2012e-02,  8.5547e-01, -1.1719e-01,  1.9922e+00,\n",
       "         -1.2422e+00, -5.5908e-02,  7.6562e-01, -2.4609e-01, -5.2734e-01,\n",
       "          3.6377e-02, -5.6250e-01, -4.2773e-01, -8.7891e-01,  3.0859e-01,\n",
       "          2.0508e-01,  1.4219e+00, -8.3984e-01,  1.0312e+00, -3.9844e-01,\n",
       "         -3.8477e-01,  1.2939e-02, -1.0156e-01, -1.1016e+00, -1.3516e+00,\n",
       "          1.3733e-02, -1.2422e+00,  8.4766e-01,  9.7266e-01, -8.3984e-01,\n",
       "         -1.5723e-01,  1.5703e+00,  4.1211e-01,  8.2031e-01,  1.0703e+00,\n",
       "          4.3359e-01,  6.6406e-01, -8.9453e-01, -1.0781e+00,  2.2363e-01,\n",
       "          3.4180e-01,  3.8086e-01,  1.1047e-02, -1.3594e+00,  2.2656e-01,\n",
       "          1.2266e+00, -2.6001e-02, -8.7891e-01, -1.1094e+00,  2.2344e+00,\n",
       "         -9.1016e-01, -1.2969e+00, -6.6016e-01, -5.0000e-01, -1.3359e+00,\n",
       "         -1.7812e+00, -5.3125e-01,  7.8125e-02, -1.5527e-01,  1.6699e-01,\n",
       "          9.6484e-01, -2.6172e-01, -8.6328e-01,  4.8218e-03, -5.2344e-01,\n",
       "          1.1406e+00,  3.5547e-01,  5.3906e-01, -2.7344e-01,  1.5234e+00,\n",
       "          8.9844e-01,  1.9062e+00, -1.5391e+00,  5.1562e-01,  1.4954e-02,\n",
       "          6.8750e-01,  2.5586e-01, -7.2937e-03, -5.5469e-01, -5.3125e-01,\n",
       "         -4.0820e-01,  2.6758e-01, -1.1250e+00, -2.2969e+00, -1.3867e-01,\n",
       "          1.2031e+00,  3.8906e+00, -4.4727e-01,  2.4375e+00,  3.3203e-01,\n",
       "         -1.0889e-01,  8.2422e-01, -6.2500e-01, -8.6719e-01, -1.6406e+00,\n",
       "         -1.5918e-01, -9.2578e-01, -1.1875e+00, -1.9043e-01, -3.3008e-01,\n",
       "         -1.6699e-01, -1.3203e+00, -7.6172e-01, -2.7539e-01, -6.8359e-01,\n",
       "          7.7344e-01,  6.2109e-01,  2.7539e-01,  2.7344e-01, -5.2734e-01,\n",
       "          1.1719e-01, -7.7344e-01,  6.5234e-01,  8.8867e-02, -4.5654e-02,\n",
       "         -2.5146e-02,  1.7031e+00,  2.1973e-02,  1.7969e+00, -1.5137e-01,\n",
       "         -1.1621e-01,  5.2344e-01, -1.1094e+00, -1.7090e-02, -1.1816e-01,\n",
       "         -6.5625e-01, -4.6631e-02,  3.1250e-01,  1.4453e+00, -1.1016e+00,\n",
       "          5.5664e-02,  2.8125e+00, -1.6504e-01,  2.0996e-01, -1.7969e+00,\n",
       "         -9.3750e-01,  1.4746e-01, -1.5078e+00, -8.6328e-01, -2.9102e-01,\n",
       "         -8.9453e-01, -2.4023e-01, -4.8828e-01,  7.3828e-01, -1.2266e+00,\n",
       "          9.1797e-01, -8.7109e-01, -1.7578e+00, -1.3047e+00, -1.6641e+00,\n",
       "         -1.4453e+00, -5.4688e-01,  1.0205e-01,  6.3281e-01, -8.9062e-01,\n",
       "         -7.3828e-01, -1.2598e-01,  6.9922e-01, -1.2578e+00, -8.0469e-01,\n",
       "         -3.2617e-01,  9.2578e-01,  6.6406e-01, -4.4141e-01,  4.4922e-01,\n",
       "          1.3828e+00,  1.6699e-01,  2.5000e+00, -3.3008e-01,  9.5703e-01,\n",
       "         -2.2656e-01, -8.5547e-01,  8.2031e-01]], device='cuda:0',\n",
       "       dtype=torch.bfloat16, grad_fn=<IndexBackward0>), hidden_states=(tensor([[[ 2.6855e-03,  5.2185e-03,  4.9591e-04,  ..., -3.1433e-03,\n",
       "           1.0681e-03,  3.4332e-03],\n",
       "         [ 7.1411e-03, -3.6621e-03, -1.3306e-02,  ..., -1.3733e-04,\n",
       "          -1.6113e-02,  1.5640e-03],\n",
       "         [-2.2888e-03, -1.5137e-02,  6.0730e-03,  ...,  2.5635e-02,\n",
       "           8.9722e-03,  4.0588e-03],\n",
       "         ...,\n",
       "         [ 2.2827e-02,  1.3306e-02, -1.1230e-02,  ..., -7.9956e-03,\n",
       "          -2.0447e-03,  8.9111e-03],\n",
       "         [ 2.0020e-02,  1.5015e-02, -8.7891e-03,  ..., -4.0283e-03,\n",
       "           1.9073e-05,  1.0864e-02],\n",
       "         [ 3.4180e-02,  3.5889e-02,  2.7710e-02,  ...,  1.4465e-02,\n",
       "           1.1108e-02, -2.5757e-02]]], device='cuda:0', dtype=torch.bfloat16,\n",
       "       grad_fn=<AddBackward0>), tensor([[[-4.2188e+00, -2.6562e+00,  5.1250e+00,  ...,  1.0078e+00,\n",
       "          -2.0000e+00, -1.1641e+00],\n",
       "         [-1.9531e-01,  1.3770e-01,  1.3281e-01,  ..., -1.7480e-01,\n",
       "          -1.6797e-01, -2.7148e-01],\n",
       "         [-1.9922e-01, -8.5449e-02,  1.2256e-01,  ...,  1.3477e-01,\n",
       "          -1.1230e-02, -3.7109e-01],\n",
       "         ...,\n",
       "         [-3.4668e-02,  3.0518e-03,  1.8921e-02,  ...,  3.0518e-04,\n",
       "           3.0762e-02, -1.5625e-02],\n",
       "         [-3.3691e-02,  6.5918e-03,  2.2339e-02,  ...,  4.5166e-03,\n",
       "           3.8086e-02, -6.2866e-03],\n",
       "         [-1.7700e-02,  4.5166e-02,  5.6152e-02,  ...,  2.1484e-02,\n",
       "           5.2002e-02, -6.2500e-02]]], device='cuda:0', dtype=torch.bfloat16,\n",
       "       grad_fn=<AddBackward0>), tensor([[[-4.1250e+00, -2.6719e+00,  5.1250e+00,  ...,  9.9219e-01,\n",
       "          -2.2344e+00, -1.1484e+00],\n",
       "         [-1.8457e-01,  1.4941e-01,  7.3242e-02,  ..., -1.3965e-01,\n",
       "          -2.7539e-01, -2.2363e-01],\n",
       "         [-2.0898e-01, -1.5234e-01,  2.1094e-01,  ...,  1.7578e-01,\n",
       "          -1.2305e-01, -2.3340e-01],\n",
       "         ...,\n",
       "         [-5.5176e-02,  3.6133e-02, -2.4292e-02,  ..., -1.7090e-02,\n",
       "           4.5776e-03, -3.6621e-02],\n",
       "         [-5.6152e-02,  3.7842e-02, -1.9287e-02,  ..., -1.2451e-02,\n",
       "           1.2390e-02, -2.8198e-02],\n",
       "         [-4.3457e-02,  7.4219e-02,  1.9043e-02,  ...,  1.8311e-02,\n",
       "           2.1973e-02, -8.0078e-02]]], device='cuda:0', dtype=torch.bfloat16,\n",
       "       grad_fn=<AddBackward0>), tensor([[[-3.9531e+00, -2.6562e+00,  4.8125e+00,  ...,  1.1484e+00,\n",
       "          -2.3438e+00, -1.1406e+00],\n",
       "         [-1.2891e-01,  2.4805e-01,  7.4219e-02,  ..., -1.9336e-01,\n",
       "          -3.0859e-01, -2.8125e-01],\n",
       "         [-1.7969e-01, -1.4062e-01,  2.1289e-01,  ...,  2.1875e-01,\n",
       "          -2.0801e-01, -7.2266e-02],\n",
       "         ...,\n",
       "         [-7.6904e-03,  6.6895e-02, -8.5449e-03,  ..., -1.5869e-02,\n",
       "           4.1016e-02, -5.7861e-02],\n",
       "         [-8.7891e-03,  7.0801e-02,  9.7656e-04,  ..., -1.3184e-02,\n",
       "           4.7119e-02, -5.1758e-02],\n",
       "         [ 1.4893e-02,  1.0645e-01,  3.5400e-02,  ...,  2.8320e-02,\n",
       "           5.6396e-02, -1.1426e-01]]], device='cuda:0', dtype=torch.bfloat16,\n",
       "       grad_fn=<AddBackward0>), tensor([[[-3.9062e+00, -2.7188e+00,  4.8125e+00,  ...,  1.2656e+00,\n",
       "          -2.3906e+00, -1.1172e+00],\n",
       "         [-1.7969e-01,  3.1445e-01,  9.3750e-02,  ..., -2.1582e-01,\n",
       "          -3.1055e-01, -2.0996e-01],\n",
       "         [-7.9590e-02, -2.5391e-01,  3.1641e-01,  ...,  2.9492e-01,\n",
       "          -2.3633e-01, -2.3730e-01],\n",
       "         ...,\n",
       "         [ 1.0303e-01,  1.4648e-03,  2.6855e-03,  ..., -1.6724e-02,\n",
       "           2.3682e-02, -1.0010e-02],\n",
       "         [ 1.0693e-01, -1.9531e-03,  1.2207e-02,  ..., -1.5015e-02,\n",
       "           3.5156e-02, -5.8594e-03],\n",
       "         [ 1.1523e-01,  4.2725e-02,  3.5645e-02,  ...,  9.7656e-03,\n",
       "           3.3936e-02, -5.8838e-02]]], device='cuda:0', dtype=torch.bfloat16,\n",
       "       grad_fn=<AddBackward0>), tensor([[[-3.9062e+00, -2.6250e+00,  4.8438e+00,  ...,  1.3125e+00,\n",
       "          -2.3438e+00, -1.0625e+00],\n",
       "         [-2.6953e-01,  4.0820e-01,  3.1738e-02,  ..., -1.8750e-01,\n",
       "          -3.1641e-01, -8.3984e-02],\n",
       "         [ 1.5625e-02, -2.7539e-01,  2.8125e-01,  ...,  3.5547e-01,\n",
       "          -2.0215e-01, -8.3008e-02],\n",
       "         ...,\n",
       "         [ 9.1797e-02,  7.8125e-02,  3.9795e-02,  ..., -6.5918e-03,\n",
       "           4.7119e-02,  2.5635e-03],\n",
       "         [ 9.0820e-02,  7.3242e-02,  5.3467e-02,  ..., -7.6904e-03,\n",
       "           5.0293e-02,  5.7373e-03],\n",
       "         [ 8.9844e-02,  1.0742e-01,  5.9570e-02,  ...,  1.4404e-02,\n",
       "           7.7637e-02, -5.0293e-02]]], device='cuda:0', dtype=torch.bfloat16,\n",
       "       grad_fn=<AddBackward0>), tensor([[[-3.8906, -2.6719,  4.8750,  ...,  1.3594, -2.3906, -1.1094],\n",
       "         [-0.3672,  0.4863,  0.2324,  ..., -0.3164, -0.3516, -0.1309],\n",
       "         [ 0.2295, -0.1050,  0.3066,  ...,  0.0957, -0.2754, -0.2598],\n",
       "         ...,\n",
       "         [-0.0322, -0.0337,  0.1738,  ..., -0.0396, -0.0615, -0.0337],\n",
       "         [-0.0225, -0.0449,  0.1914,  ..., -0.0430, -0.0620, -0.0309],\n",
       "         [-0.0396, -0.0405,  0.1758,  ..., -0.0083, -0.0322, -0.0688]]],\n",
       "       device='cuda:0', dtype=torch.bfloat16, grad_fn=<AddBackward0>), tensor([[[-3.8906, -2.5469,  4.9062,  ...,  1.3594, -2.4062, -1.1016],\n",
       "         [-0.3633,  0.5898,  0.2520,  ..., -0.3594, -0.3711, -0.0762],\n",
       "         [ 0.5156,  0.0181,  0.2295,  ...,  0.1953, -0.5664, -0.2812],\n",
       "         ...,\n",
       "         [ 0.0225,  0.1406,  0.1650,  ...,  0.0830,  0.0552,  0.0101],\n",
       "         [ 0.0181,  0.1377,  0.1758,  ...,  0.0850,  0.0542,  0.0088],\n",
       "         [-0.0142,  0.1562,  0.1836,  ...,  0.1030,  0.0488, -0.0122]]],\n",
       "       device='cuda:0', dtype=torch.bfloat16, grad_fn=<AddBackward0>), tensor([[[-3.8281, -2.7344,  5.0000,  ...,  1.3750, -2.4531, -1.1562],\n",
       "         [-0.3691,  0.5117,  0.3691,  ..., -0.3906, -0.4531, -0.0122],\n",
       "         [ 0.7383, -0.2344,  0.2383,  ...,  0.4141, -0.4297, -0.5000],\n",
       "         ...,\n",
       "         [-0.0347, -0.0566,  0.2158,  ...,  0.1113,  0.1875, -0.0552],\n",
       "         [-0.0420, -0.0674,  0.2188,  ...,  0.1094,  0.1836, -0.0459],\n",
       "         [-0.0522, -0.0540,  0.2793,  ...,  0.1367,  0.2051, -0.0957]]],\n",
       "       device='cuda:0', dtype=torch.bfloat16, grad_fn=<AddBackward0>), tensor([[[-3.9375e+00, -2.5469e+00,  4.9375e+00,  ...,  1.1875e+00,\n",
       "          -2.5000e+00, -1.0781e+00],\n",
       "         [-3.2812e-01,  6.7578e-01,  3.5547e-01,  ..., -5.4688e-01,\n",
       "          -4.7266e-01, -1.5503e-02],\n",
       "         [ 1.1250e+00, -1.4648e-01,  2.3340e-01,  ...,  1.9141e-01,\n",
       "          -4.5117e-01, -4.9219e-01],\n",
       "         ...,\n",
       "         [ 3.6377e-02,  2.4170e-02,  3.7891e-01,  ...,  1.9043e-02,\n",
       "           8.6914e-02, -7.6172e-02],\n",
       "         [ 3.1250e-02,  1.7090e-02,  3.7891e-01,  ...,  2.1973e-02,\n",
       "           9.0820e-02, -7.3242e-02],\n",
       "         [-6.1035e-04,  4.1016e-02,  4.6484e-01,  ...,  5.8105e-02,\n",
       "           8.6914e-02, -1.3770e-01]]], device='cuda:0', dtype=torch.bfloat16,\n",
       "       grad_fn=<AddBackward0>), tensor([[[-3.8906, -2.4375,  4.9375,  ...,  1.1484, -2.4375, -1.0625],\n",
       "         [-0.2656,  0.5938,  0.6367,  ..., -0.7227, -0.7969, -0.0050],\n",
       "         [ 1.2031, -0.2520, -0.0078,  ...,  0.2598, -0.1055, -0.5234],\n",
       "         ...,\n",
       "         [ 0.4316, -0.0303,  0.6367,  ...,  0.1992, -0.0942,  0.0752],\n",
       "         [ 0.4102, -0.0439,  0.6328,  ...,  0.2031, -0.0767,  0.0757],\n",
       "         [ 0.3945,  0.0059,  0.8125,  ...,  0.2422, -0.1406, -0.0278]]],\n",
       "       device='cuda:0', dtype=torch.bfloat16, grad_fn=<AddBackward0>), tensor([[[-3.8750, -2.5312,  4.7812,  ...,  1.1172, -2.2656, -1.2656],\n",
       "         [-0.1445,  0.7500,  0.4766,  ..., -0.9609, -0.6797, -0.1221],\n",
       "         [ 0.9414, -0.4258,  0.1104,  ...,  0.1338,  0.1533, -0.6562],\n",
       "         ...,\n",
       "         [ 0.2617, -0.1768,  0.7852,  ...,  0.1367, -0.3887, -0.2266],\n",
       "         [ 0.2451, -0.1836,  0.7812,  ...,  0.1523, -0.3750, -0.2402],\n",
       "         [ 0.2949, -0.0850,  1.0156,  ...,  0.2441, -0.3750, -0.3359]]],\n",
       "       device='cuda:0', dtype=torch.bfloat16, grad_fn=<AddBackward0>), tensor([[[-3.4688e+00, -2.9688e+00,  5.1875e+00,  ...,  1.3438e+00,\n",
       "          -1.6953e+00, -1.2656e+00],\n",
       "         [-7.8125e-03,  4.8438e-01,  1.0156e+00,  ..., -8.9062e-01,\n",
       "          -1.7578e-01, -3.4375e-01],\n",
       "         [ 1.2031e+00, -8.0859e-01,  5.6641e-01,  ...,  1.2891e-01,\n",
       "           4.6484e-01, -8.1250e-01],\n",
       "         ...,\n",
       "         [ 7.1875e-01, -3.9453e-01,  1.3281e+00,  ...,  5.7031e-01,\n",
       "          -5.0781e-01,  1.9531e-02],\n",
       "         [ 6.8750e-01, -3.9844e-01,  1.3359e+00,  ...,  5.7812e-01,\n",
       "          -4.8828e-01, -1.9531e-03],\n",
       "         [ 7.5000e-01, -3.6719e-01,  1.5938e+00,  ...,  6.6406e-01,\n",
       "          -4.9219e-01, -9.3750e-02]]], device='cuda:0', dtype=torch.bfloat16,\n",
       "       grad_fn=<AddBackward0>)), attentions=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prompt_embeds) # length:3\n",
    "prompt_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c78e256",
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_prompt_embeds = prompt_embeds[0]\n",
    "prompt_embeds = prompt_embeds.hidden_states[-2]\n",
    "print(pooled_prompt_embeds.shape,prompt_embeds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9b55759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 77]) torch.Size([1, 77])\n"
     ]
    }
   ],
   "source": [
    "text_input_ids = tokenizer_one(\n",
    "    prompt,\n",
    "    padding=\"max_length\",\n",
    "    max_length=tokenizer_one.model_max_length,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    ").input_ids\n",
    "\n",
    "text_input_ids_2 = tokenizer_two(\n",
    "    prompt,\n",
    "    padding=\"max_length\",\n",
    "    max_length=tokenizer_two.model_max_length,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    ").input_ids\n",
    "print(text_input_ids.shape,text_input_ids_2.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
